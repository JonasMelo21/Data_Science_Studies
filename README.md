# Estudos Ci√™ncia de Dados

Reposit√≥rio dos meus estudos em Ci√™ncia de Dados, com foco em **an√°lise cr√≠tica**, **limpeza de dados** e **modelagem supervisionada** com interpreta√ß√£o estat√≠stica.

## Projetos

---

### Projeto 01: Classifica√ß√£o da Performance de Estudantes ‚Äî Limpeza, An√°lise e Balanceamento  
**üîó Link para o notebook ‚Üí [projeto1.ipynb](projeto1.ipynb)**

Projeto de classifica√ß√£o baseado em dados educacionais (idade, etnia, faltas, etc.), com forte √™nfase em prepara√ß√£o de dados e decis√µes fundamentadas. Pois sem o pr√©-processamento correto, um aspecto *indesejado* teria enviesado a an√°lise e o treinamento do modelo desde o in√≠cio.

> O projeto melhorou minha capacidade de identificar falhas na estrutura do dataset, como valores inconsistentes nas colunas, aplicar t√©cnicas apropriadas de balanceamento e construir um pipeline de classifica√ß√£o confi√°vel e bem justificado.

**Pontos-chave:**

- **Corre√ß√£o da vari√°vel alvo:** A coluna `GradeClass`, que representa faixas de GPA, apresentava classifica√ß√µes incorretas ‚Äî alunos com nota abaixo de 3.5 estavam rotulados como se tivessem nota acima. Refiz a segmenta√ß√£o com base no GPA real. Sem essa corre√ß√£o, a an√°lise e o modelo estariam enviesados desde o in√≠cio.
- **Desbalanceamento identificado:** Diversas colunas apresentavam forte desequil√≠brio entre as classes, tanto nas vari√°veis preditoras quanto na vari√°vel alvo.
- **Uso de SMOTE:** Ap√≥s an√°lise da distribui√ß√£o, utilizei SMOTE para balancear as classes da vari√°vel alvo, garantindo que o modelo n√£o fosse tendencioso. A t√©cnica foi aplicada **ap√≥s o split de treino e teste**, evitando vazamento de dados.

**Resultados:**

- **Acur√°cia:** 96%
- **F1-score (macro):** 0.96
- **Desempenho est√°vel** em todas as classes, mesmo com dados originalmente desbalanceados.

---

### Projeto 02: Previs√£o de Churn com EDA, Testes Estat√≠sticos e Rede Neural Multicamadas (MLP)  
**üîó Link para o notebook ‚Üí [projeto2.ipynb](projeto2.ipynb)**

Neste projeto, desenvolvi uma **rede neural perceptron multicamadas (MLP)** para prever **quais clientes t√™m maior probabilidade de deixar a empresa (churn)** com base em dados demogr√°ficos e comportamentais. O projeto integrou **an√°lise explorat√≥ria detalhada**, **testes estat√≠sticos de hip√≥teses**, **balanceamento de dados com SMOTE** e a constru√ß√£o de um pipeline robusto com redes neurais.

> Essa experi√™ncia me permitiu integrar m√©todos estat√≠sticos com redes neurais, validando hip√≥teses de neg√≥cio com testes cl√°ssicos e depois transformando os dados em insights para uma arquitetura de aprendizado profundo.

**Hip√≥teses testadas e validadas:**

- **Mulheres apresentam 1.5x mais churn** que os homens (üîé Teste do Qui-Quadrado).
- **Sal√°rio n√£o tem influ√™ncia estat√≠stica significativa** no churn (üîé Teste de Mann-Whitney).
- **N√∫mero de produtos influencia o churn de forma n√£o-linear** (üîé Teste de Kruskal-Wallis).
- Identifica√ß√£o de vari√°veis com **classes desbalanceadas**, tratadas com **SMOTE** ap√≥s o split.

**Modelagem:**

- Rede neural **Multilayer Perceptron (MLP)** com fun√ß√£o de ativa√ß√£o ReLU e sa√≠da sigmoid.
- Dados normalizados e balanceados.
- Fun√ß√£o de custo: Binary Crossentropy  
- Otimizador: Adam

**Resultados do modelo:**

- **Acur√°cia:** 82%
- **F1-Score:** 59%
- **Precision:** 54% ‚Äî presen√ßa de falsos positivos (clientes previstos como churn, mas que n√£o sa√≠ram).
- **Recall:** 67% ‚Äî o modelo capturou 67% dos churns reais.

**Erros principais:**

- **226 falsos positivos:** clientes que ficaram, mas foram classificados como churn.
- **131 falsos negativos:** clientes que sa√≠ram, mas n√£o foram detectados.

**Fatores relevantes para churn identificados na an√°lise:**

- **Idade > 40 anos:** risco 2x maior de churn.
- **Clientes da Alemanha:** taxa de churn de 32% (vs. 16% na Fran√ßa).
- **Clientes inativos (`IsActiveMember=0`)**: 27% de churn (vs. 15% entre os ativos).
- **Saldo elevado (> ‚Ç¨100 mil):** mais propensos a sair.

**Possibilidade de melhoria:**

- Ajustar o **limiar de decis√£o (threshold)** da MLP para melhorar o recall e reduzir os falsos negativos.
- Explorar regulariza√ß√£o ou arquiteturas mais profundas para maior capacidade de generaliza√ß√£o.

---

Mais projetos ser√£o adicionados em breve, abordando problemas reais com foco em an√°lise de dados, valida√ß√£o estat√≠stica e aplica√ß√£o pr√°tica de modelos preditivos e redes neurais.
