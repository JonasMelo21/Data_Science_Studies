# Estudos CiÃªncia de Dados

RepositÃ³rio dos meus estudos em CiÃªncia de Dados, com foco em **anÃ¡lise crÃ­tica**, **limpeza de dados** e **modelagem supervisionada** com interpretaÃ§Ã£o estatÃ­stica.

## Projetos

---

### Projeto 01: ClassificaÃ§Ã£o da Performance de Estudantes â€” Limpeza, AnÃ¡lise e Balanceamento  
**ğŸ”— Link para o notebook â†’ [projeto1.ipynb](projeto1.ipynb)**

Projeto de classificaÃ§Ã£o baseado em dados educacionais (idade, etnia, faltas, etc.), com forte Ãªnfase em preparaÃ§Ã£o de dados e decisÃµes fundamentadas. Pois sem o prÃ©-processamento correto, um aspecto *indesejado* teria enviesado a anÃ¡lise e o treinamento do modelo desde o inÃ­cio.

> O projeto melhorou minha capacidade de identificar falhas na estrutura do dataset, como valores inconsistentes nas colunas, aplicar tÃ©cnicas apropriadas de balanceamento e construir um pipeline de classificaÃ§Ã£o confiÃ¡vel e bem justificado.

**Pontos-chave:**

- **CorreÃ§Ã£o da variÃ¡vel alvo:** A coluna `GradeClass`, que representa faixas de GPA, apresentava classificaÃ§Ãµes incorretas â€” alunos com nota abaixo de 3.5 estavam rotulados como se tivessem nota acima. Refiz a segmentaÃ§Ã£o com base no GPA real. Sem essa correÃ§Ã£o, a anÃ¡lise e o modelo estariam enviesados desde o inÃ­cio.
- **Desbalanceamento identificado:** Diversas colunas apresentavam forte desequilÃ­brio entre as classes, tanto nas variÃ¡veis preditoras quanto na variÃ¡vel alvo.
- **Uso de SMOTE:** ApÃ³s anÃ¡lise da distribuiÃ§Ã£o, utilizei SMOTE para balancear as classes da variÃ¡vel alvo, garantindo que o modelo nÃ£o fosse tendencioso. A tÃ©cnica foi aplicada **apÃ³s o split de treino e teste**, evitando vazamento de dados.

**Resultados:**

- **AcurÃ¡cia:** 96%
- **F1-score (macro):** 0.96
- **Desempenho estÃ¡vel** em todas as classes, mesmo com dados originalmente desbalanceados.

---

### Projeto 02: PrevisÃ£o de Churn com EDA, Testes EstatÃ­sticos e Rede Neural (MLP)

ğŸ”— **[Notebook do Projeto](projeto2.ipynb)**

Desenvolvi um modelo preditivo para identificar clientes com maior risco de **churn**, integrando **anÃ¡lise exploratÃ³ria**, **testes estatÃ­sticos de hipÃ³teses** e uma **rede neural MLP**.

O projeto evidenciou raciocÃ­nio analÃ­tico ao combinar **validaÃ§Ã£o estatÃ­stica de hipÃ³teses de negÃ³cio** com tÃ©cnicas de **machine learning supervisionado**, garantindo uma abordagem robusta e interpretÃ¡vel.

---

#### ğŸ” Principais insights e hipÃ³teses validadas:

* **GÃªnero:** mulheres tÃªm 1.5x mais chance de churn (*Teste do Qui-Quadrado*).
* **SalÃ¡rio:** sem influÃªncia estatÃ­stica significativa (*Teste de Mann-Whitney*).
* **NÃºmero de produtos:** relaÃ§Ã£o nÃ£o-linear com churn (*Teste de Kruskal-Wallis*).
* Dados desbalanceados tratados com **SMOTE**, aplicado apÃ³s o *split* para evitar vazamento de informaÃ§Ã£o.

---

#### ğŸ§  Modelagem com Rede Neural MLP:

* Arquitetura: Perceptron multicamadas com ReLU e saÃ­da sigmoid
* NormalizaÃ§Ã£o dos dados e funÃ§Ã£o de custo: *Binary Crossentropy*
* Otimizador: **Adam**

**MÃ©tricas de desempenho:**

* **AcurÃ¡cia:** 82%
* **F1-Score:** 59%
* **Recall:** 67% (captura da maioria dos churns reais)
* **Precision:** 54% (alguns falsos positivos)

---

#### ğŸ’¡ Fatores de churn identificados:

* **Idade > 40:** risco 2x maior
* **Clientes da Alemanha:** 32% de churn (vs. 16% na FranÃ§a)
* **Clientes inativos:** churn de 27% (vs. 15% dos ativos)
* **Saldo alto (> â‚¬100 mil):** maior propensÃ£o a sair

---

#### ğŸš€ PrÃ³ximos passos:

* Ajustar o **threshold de decisÃ£o** para reduzir falsos negativos
* Testar arquiteturas mais profundas e regularizaÃ§Ã£o para melhorar generalizaÃ§Ã£o

---

Mais projetos serÃ£o adicionados em breve, abordando problemas reais com foco em anÃ¡lise de dados, validaÃ§Ã£o estatÃ­stica e aplicaÃ§Ã£o prÃ¡tica de modelos preditivos e redes neurais.
