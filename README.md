# ğŸ“š Estudos em CiÃªncia de Dados

RepositÃ³rio dos meus estudos em **CiÃªncia de Dados**, com foco em:

- ğŸ§¼ Limpeza e prÃ©-processamento de dados
- ğŸ“Š AnÃ¡lise exploratÃ³ria e interpretaÃ§Ã£o estatÃ­stica
- ğŸ¤– Modelos supervisionados com raciocÃ­nio crÃ­tico
- ğŸ§  Aprendizado a partir de erros e validaÃ§Ãµes

---

## âš¡ VisÃ£o Geral dos Projetos

### âœ… Projeto 01: ClassificaÃ§Ã£o da Performance de Estudantes  
ğŸ“Œ **ClassificaÃ§Ã£o supervisionada com foco em limpeza de dados e correÃ§Ã£o de erro crÃ­tico no dataset original.**  
Corrigi manualmente os rÃ³tulos da variÃ¡vel alvo, que estavam errados no prÃ³prio Kaggle, usei SMOTE de forma segura (apÃ³s o split) e obtive **96% de acurÃ¡cia e F1-score macro de 0.96**, com desempenho equilibrado nas classes.

### ğŸš¨ Projeto 02: PrevisÃ£o de Churn com Testes EstatÃ­sticos e Rede Neural  
ğŸ“Œ **CombinaÃ§Ã£o de estatÃ­stica inferencial com machine learning supervisionado.**  
Usei testes como Qui-quadrado, Mann-Whitney e Kruskal-Wallis para validar hipÃ³teses de negÃ³cio antes de treinar uma MLP. O projeto mostra capacidade de transformar dados em decisÃµes orientadas e interpretÃ¡veis.

### ğŸ™ï¸ Projeto 03: PrevisÃ£o de PreÃ§o de Aluguel com RegressÃ£o Linear e ClassificaÃ§Ã£o  
ğŸ“Œ **AnÃ¡lise de impacto de variÃ¡veis reais (Ã¡rea, garagem, distÃ¢ncia do centro) sobre o preÃ§o de aluguel.**  
O modelo atingiu **RÂ² de 0.82** e gerou coeficientes interpretÃ¡veis. TambÃ©m classifiquei se o imÃ³vel estÃ¡ "caro ou barato", com **84% de acurÃ¡cia** e insights prÃ¡ticos para melhorar a performance.

---

## ğŸ“ Projetos Detalhados

---

### ğŸ§ª Projeto 01: ClassificaÃ§Ã£o da Performance de Estudantes  
ğŸ”— **[Notebook â†’ projeto1.ipynb](projeto1.ipynb)**

> ClassificaÃ§Ã£o baseada em dados educacionais (idade, etnia, faltas, etc.), com foco em decisÃµes bem fundamentadas desde o prÃ©-processamento.

**ğŸŒŸ Destaques:**

- Corrigi um **erro do dataset original** na coluna `GradeClass`, que estava rotulando mal os alunos com GPA baixo.
- Identifiquei desbalanceamento severo e usei **SMOTE com seguranÃ§a**, apÃ³s o split, evitando vazamento.
- ConstruÃ­ pipeline robusto com foco em evitar enviesamentos.

**ğŸ“Š Resultados:**

- **AcurÃ¡cia:** 96%
- **F1-score (macro):** 0.96
- **Desempenho estÃ¡vel** mesmo com dados desbalanceados

---

### ğŸ§  Projeto 02: PrevisÃ£o de Churn com EDA, Testes EstatÃ­sticos e Rede Neural  
ğŸ”— **[Notebook â†’ projeto2.ipynb](projeto2.ipynb)**

> PrediÃ§Ã£o de churn integrando **estatÃ­stica inferencial** com **redes neurais**, garantindo nÃ£o sÃ³ performance, mas **interpretaÃ§Ã£o e confianÃ§a nos dados**.

**ğŸ”¬ Testes de hipÃ³teses aplicados:**

- Qui-quadrado â†’ ğŸ“Œ GÃªnero influencia no churn
- Mann-Whitney â†’ ğŸ“Œ SalÃ¡rio **nÃ£o** tem impacto significativo
- Kruskal-Wallis â†’ ğŸ“Œ NÂº de produtos tem relaÃ§Ã£o nÃ£o-linear com churn

**ğŸ¤– Modelagem com MLP:**

- Perceptron multicamadas com ReLU e saÃ­da Sigmoid
- Otimizador **Adam**, funÃ§Ã£o de perda **Binary Crossentropy**
- Dados normalizados e balanceados com SMOTE

**ğŸ“ˆ Resultados:**

- **AcurÃ¡cia:** 82%
- **F1-Score:** 59%
- **Recall:** 67%
- **Precision:** 54%

**ğŸ’¡ Insights prÃ¡ticos:**

- Idade > 40 aumenta risco 2x
- Clientes da Alemanha tÃªm maior taxa de churn
- Clientes inativos e com saldo alto saem mais

---

### ğŸ  Projeto 03: PrevisÃ£o de Aluguel com RegressÃ£o Linear e ClassificaÃ§Ã£o  
ğŸ”— **[Notebook â†’ projeto3.ipynb](projeto3.ipynb)**

> Estimativa do valor de aluguel de apartamentos e classificaÃ§Ã£o como **caro ou barato** baseado em dados reais de Ã¡rea, quartos, banheiros, garagem e localizaÃ§Ã£o.

**ğŸ” EDA â€” principais descobertas:**

- **Ãrea (mÂ²)** tem forte impacto positivo no preÃ§o  
- **DistÃ¢ncia do centro** tem impacto negativo  
- Modelo revela coeficientes intuitivos e Ãºteis

**ğŸ“‰ RegressÃ£o Linear â€” Resultados:**

- **MAE:** R$158,61
- **RÂ² Score:** 0.82
- **Coeficientes:**
  - +R$24,03/mÂ²
  - +R$123,95/quarto
  - +R$101,11/banheiro
  - +R$196,86 com garagem
  - â€“R$51,10/km de distÃ¢ncia do centro

**ğŸ“Š ClassificaÃ§Ã£o: Caro ou Barato**

- **AcurÃ¡cia:** 84%
- **PrecisÃ£o:** 87%
- **Recall:** 83%
- âš ï¸ 18 falsos negativos â€” imÃ³veis caros classificados como baratos

**ğŸš§ Melhorias sugeridas:**

- Engenharia de atributos
- RemoÃ§Ã£o de outliers
- Testes com modelos mais robustos (Random Forest, SVM, Gradient Boosting)

---

ğŸ“Œ *Mais projetos serÃ£o adicionados em breve, com foco em desafios reais, validaÃ§Ã£o estatÃ­stica e soluÃ§Ãµes de alto valor analÃ­tico.*

